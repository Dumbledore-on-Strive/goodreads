{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "duplicate-cookbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "#important libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests as rq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "molecular-agent",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://www.goodreads.com/list/show/1043.Books_That_Should_Be_Made_Into_Movies'\n",
    "\n",
    "def get_books_url_per_page(base_url, tag, tag_class):\n",
    "\n",
    "    book_url_list = []\n",
    "    base_page = rq.get(base_url)\n",
    "    base_content = BeautifulSoup(base_page.content, 'html.parser')\n",
    "\n",
    "    for a in base_content.find_all(tag, class_= tag_class):\n",
    "        book_url_list.append('https://www.goodreads.com/' + a['href'])\n",
    "    \n",
    "    return book_url_list\n",
    "\n",
    "\n",
    "def get_base_page_list(base_url, n):\n",
    "    base_page_list = []\n",
    "    for i in range(n):\n",
    "        base_page_list.append(base_url + str(i + 1))\n",
    "    \n",
    "    return base_page_list\n",
    "\n",
    "whole_book_url_list = []\n",
    "\n",
    "for link in get_base_page_list('https://www.goodreads.com/list/show/1043.Books_That_Should_Be_Made_Into_Movies?page=', 10):\n",
    "    whole_book_url_list.append(get_books_url_per_page(link, 'a', 'bookTitle'))\n",
    "\n",
    "whole_book_url_list = [link for subs in whole_book_url_list for link in subs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breeding-genetics",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "whole_book_url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "middle-cable",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title(page_soup):\n",
    "    try :\n",
    "        title = page_soup.find('h1', {\"id\":\"bookTitle\"}).text.strip()\n",
    "        return title\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flying-cleveland",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_author(page_soup):\n",
    "    try :\n",
    "        author = page_soup.find(\"a\", {\"class\":\"authorName\"}).text.strip()\n",
    "        return author\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transparent-serial",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_rating(page_soup):\n",
    "    try :\n",
    "        num_rating=int(page_soup.find(itemprop=\"ratingCount\").text.strip().replace(\"ratings\", \"\").replace(\",\", \"\"))\n",
    "        return num_rating\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dense-foster",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_reviews(page_soup):\n",
    "    try :\n",
    "        num_review=page_soup.find(itemprop=\"reviewCount\").text.replace(\"reviews\", \"\").replace(\",\", \"\").strip()\n",
    "        return int(num_review)\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preliminary-berkeley",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_rating(page_soup):\n",
    "    try :\n",
    "        avg_rating=page_soup.find(\"span\", itemprop=\"ratingValue\").text.strip()\n",
    "        return float(avg_rating)\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "early-optimization",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_pages(page_soup):\n",
    "    try :\n",
    "        num_pages=page_soup.find(itemprop=\"numberOfPages\").text.strip().replace(\"pages\", \"\")\n",
    "        return int(num_pages)\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cloudy-dancing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_original_publish_year(page_soup):\n",
    "    try :\n",
    "        original_publish_year=page_soup.find_all(\"div\", class_=\"row\")[1].text.split()[3]\n",
    "        return original_publish_year\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dress-member",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_series(page_soup):\n",
    "    try:\n",
    "        series = page_soup.find(id=\"bookSeries\").text.strip() \n",
    "        if len(series)!= 0:\n",
    "            return True\n",
    "        else: \n",
    "            return False\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prostate-meditation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_genres(page_soup):\n",
    "    try:\n",
    "        g_list=[]\n",
    "        genres = page_soup.find('div',class_=\"rightContainer\").find_all(class_=\"left\")\n",
    "        for row in genres:\n",
    "            row=row.text.replace(\">\",\"\").strip().split()\n",
    "            row=\" \".join(row)\n",
    "            g_list.append(row)\n",
    "        return g_list\n",
    "    except:\n",
    "        return np.nan    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "racial-attempt",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_award(page_soup):\n",
    "    try:\n",
    "        count=0\n",
    "        awards = page_soup.find(\"div\", {\"itemprop\": \"awards\"}).find_all('a')\n",
    "        for award in awards:\n",
    "            if award!=None:\n",
    "                count+=1\n",
    "        return count\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "previous-convention",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_place(page_soup):\n",
    "    try:\n",
    "        place = page_soup.find(\"div\", {'id':\"bookDataBox\"}).find('span',class_=\"darkGreyText\").text.replace(\"(\",\"\").replace(\")\",\"\").strip()\n",
    "        return place\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "furnished-surgeon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_frame(links):\n",
    "    data_frame=[]\n",
    "    for url  in  links:\n",
    "        page_html = rq.get(url)\n",
    "        page_soup = BeautifulSoup(page_html.content, 'html.parser')\n",
    "        title=get_title(page_soup)\n",
    "      \n",
    "        author=get_author(page_soup)\n",
    "      \n",
    "        num_rating=get_num_rating(page_soup)\n",
    "       \n",
    "        num_reviews=get_num_reviews(page_soup)\n",
    "       \n",
    "        avg_rating=get_avg_rating(page_soup)\n",
    "        \n",
    "        num_pages=get_num_pages(page_soup)\n",
    "      \n",
    "        original_publish_year=get_original_publish_year(page_soup)\n",
    "        \n",
    "        series=get_series(page_soup)\n",
    "       \n",
    "        genres=get_genres(page_soup)\n",
    "       \n",
    "        award=get_award(page_soup)\n",
    "       \n",
    "        place=get_place(page_soup)\n",
    "        dictionary={\n",
    "            \"title\": title,\n",
    "            \"author\": author,\n",
    "            \"num_rating\": num_rating,\n",
    "            \"num_reviews\": num_reviews,\n",
    "            \"avg_rating\": avg_rating,\n",
    "            \"num_pages\": num_pages,\n",
    "            \"original_publish_year\": original_publish_year,\n",
    "            \"series\": series,\n",
    "            \"genres\": genres,\n",
    "            \"award\": award,\n",
    "            \"place\": place,\n",
    "            \"url\": url\n",
    "        }\n",
    "        data_frame.append(dictionary)\n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overall-exchange",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=get_data_frame(whole_book_url_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mighty-opera",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deadly-shopping",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)\n",
    "  \n",
    "# saving the dataframe\n",
    "df.to_csv('df.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
